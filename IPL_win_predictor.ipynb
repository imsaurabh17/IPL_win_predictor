{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ece155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b202e44",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'matches.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatches.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m delivery \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeliveries.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'matches.csv'"
     ]
    }
   ],
   "source": [
    "match = pd.read_csv('matches.csv')\n",
    "delivery = pd.read_csv('deliveries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "match.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d772c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc53ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae09f0",
   "metadata": {},
   "source": [
    "Now I want to find out the runs scored by a team in every innings so for that I will use groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf73b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.groupby(['match_id','inning']).sum()['total_runs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77458aef",
   "metadata": {},
   "source": [
    "You can clearly observe from the above code that we are getiing the runs scored by each team in each innings of evry match.\n",
    "Now i will use reset_index to convert this into dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.groupby(['match_id','inning']).sum()['total_runs'].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165901b",
   "metadata": {},
   "source": [
    "I will save this code in a variable called as total_score_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ec9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score_df = delivery.groupby(['match_id','inning']).sum()['total_runs'].reset_index()\n",
    "total_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc76d2",
   "metadata": {},
   "source": [
    "Now we will only take the total_runs of 1st innings. so we will ignore the 2nd innings score. Why? we will see this ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score_df = total_score_df[total_score_df['inning']==1]\n",
    "total_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba065ad4",
   "metadata": {},
   "source": [
    "We will merge this dataframe with match dataframe because we have all the details in the match dataframe except the runs scored by a team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df=match.merge(total_score_df[['match_id','total_runs']],left_on = 'id',right_on='match_id')\n",
    "match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df['team1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7ddbe",
   "metadata": {},
   "source": [
    "As we all know previously there were few teams who are not the part of IPL anymore(eg.'Pune Warriors'etc) and also few teams who have twoo different names\n",
    "(eg. 'Delhi Daredevils','Delhi capitals'etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6719c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [\n",
    "    'Sunrisers Hyderabad',\n",
    "    'Mumbai Indians',\n",
    "    'Royal Challengers Bangalore',\n",
    "    'Kolkata Knight Riders',\n",
    "    'Kings XI Punjab',\n",
    "    'Chennai Super Kings',\n",
    "    'Rajasthan Royals',\n",
    "    'Delhi Capitals'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d76bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df['team1']=match_df['team1'].str.replace('Delhi Daredevils','Delhi Capitals')\n",
    "match_df['team2']=match_df['team2'].str.replace('Delhi Daredevils','Delhi Capitals')\n",
    "\n",
    "match_df['team1']=match_df['team1'].str.replace('Deccan Chargers','Sunrisers Hyderabad')\n",
    "match_df['team2']=match_df['team2'].str.replace('Deccan Chargers','Sunrisers Hyderabad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55304cc",
   "metadata": {},
   "source": [
    "I am wring code for the match_df dataframe and I want only those teams who are part of the IPL. The teams who are part of the IPL till now are stored in a list called teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279234ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = match_df[match_df['team1'].isin(teams)]\n",
    "match_df = match_df[match_df['team2'].isin(teams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47683831",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df['dl_applied'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321f9d9",
   "metadata": {},
   "source": [
    "I want only those matches which are not affected by the rains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c447666",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df=match_df[match_df['dl_applied']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb45dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4799b3da",
   "metadata": {},
   "source": [
    "Now I will take all the neccesary columns from this df and join that with the delivery df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81838b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df=match_df[['match_id','city','winner','total_runs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.merge(delivery,on='match_id').head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a1a750",
   "metadata": {},
   "source": [
    "we have every balls details, like the ball was bowled in which city,who was the winner of that match, target for the 2nd innings etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b294077",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df = match_df.merge(delivery,on='match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f5f4f",
   "metadata": {},
   "source": [
    "Now I only need for those innings record where the inning no is 2. It will help us for our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df = delivery_df[delivery_df['inning']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afaa645",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e8f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b6093a",
   "metadata": {},
   "source": [
    "In this df we have a column called as total_runs_y which gives us a details of runs scored on evry ball.Now we have to find out according to every match after each delivery what's the score.\n",
    "To calculate this we have to group it according to match_id and then we have to apply the function called as cumsum on total_runs_y. we will store this value in a new column called as current score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac295493",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df['current_score']=delivery_df.groupby('match_id').cumsum()['total_runs_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709588b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fdf572",
   "metadata": {},
   "source": [
    "Now we will subtract the current_score with target which will be our runs left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a91db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df['runs_left'] = delivery_df['total_runs_x']+1 - delivery_df['current_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357ca86",
   "metadata": {},
   "source": [
    "To calculate the balls_left column we have to use one mathematical formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30faf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df['balls_left'] = 126-(delivery_df['over']*6+delivery_df['ball'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a4e485",
   "metadata": {},
   "source": [
    "Now we will find out wickets left after each delivery. This will be tricky to find out but we will do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a0349",
   "metadata": {},
   "source": [
    "First we will go through the player_dismmised column and try to convert the Nan values into string of 0 after that we will convert the players name who got dismmised into string of 1.Then we will convert the column datatype into int.Then we used cumsum function on player_dismmised column while grouping it by match_id column which will give us the value of wicket lost.To calculate the wickets left we will simply subtract it by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df['player_dismissed'] = delivery_df['player_dismissed'].fillna(\"0\")\n",
    "delivery_df['player_dismissed'] = delivery_df['player_dismissed'].apply(lambda x:x if x==\"0\" else \"1\")\n",
    "delivery_df['player_dismissed'] = delivery_df['player_dismissed'].astype('int')\n",
    "wickets = delivery_df.groupby('match_id').cumsum()['player_dismissed'].values\n",
    "delivery_df['wickets'] = 10-wickets\n",
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4c909",
   "metadata": {},
   "source": [
    "Now we will calculate current run rate column. We will calculate it by dividing the runs/overs.SInce we don't have the overs column we will take the help of balls left column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df['crr']=delivery_df['current_score']/((120-delivery_df['balls_left'])/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df4c7c9",
   "metadata": {},
   "source": [
    "Now we will calculate Required run rate column.To calculate required run rate column we will perform run_left/overs_left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df['rrr'] = (delivery_df['runs_left']*6)/delivery_df['balls_left']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2f71e61",
   "metadata": {},
   "source": [
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e3f5a",
   "metadata": {},
   "source": [
    "Now we will calculate the result column where we will get to know whether chasing team won or not. If they won we will represent it as 1 else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a2c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(row):\n",
    "    return 1 if row['batting_team']==row['winner'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df['result']=delivery_df.apply(result,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a23c9e",
   "metadata": {},
   "source": [
    "Now we will take out the required columns from the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = delivery_df[['batting_team','bowling_team','city','runs_left','balls_left','wickets','total_runs_x','crr','rrr','result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab9785",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18791374",
   "metadata": {},
   "source": [
    "Now we will shuffle this df to ignore the biassedness in our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4719178",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.sample(final_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded56820",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75875f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb44aa",
   "metadata": {},
   "source": [
    "Now we will build the model. First we will split the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aecd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.iloc[:,:-1]\n",
    "Y = final_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b142fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=7,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae35755",
   "metadata": {},
   "source": [
    "As we already know that ML works only with numbers not with strings. So we will apply One Hot Encoding to convert the strings into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff22d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "trf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('trf', OneHotEncoder(sparse=False), ['batting_team', 'bowling_team', 'city'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f435d3f",
   "metadata": {},
   "source": [
    "Now we will create one pipeline where in first step we will have the above transformer and in the next step we will be having our Logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfedc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('step1',trf),\n",
    "    ('step2',LogisticRegression(solver='liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd926f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3156c",
   "metadata": {},
   "source": [
    "We are getting the above ERROR because we have null values. So first we will drop alll the null values and then rerun the X_train,X_test code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a94292",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51522c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9c6ce",
   "metadata": {},
   "source": [
    "We can clearly observe that in the rrr column we have inf values which is creating the issue. So to  overcome this error we will ignore those rows where we have 0 balls left and will re run the model building code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ac1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df['balls_left']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b2d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bd308f",
   "metadata": {},
   "source": [
    "Now we will check the model score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c10736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc88348",
   "metadata": {},
   "source": [
    "Now we will convert this model into web. For that we require teams,City and Pipeline(Pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ee8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1485f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a601052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pipe,open('pipe.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394831cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn==1.4.1.post1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986711df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
